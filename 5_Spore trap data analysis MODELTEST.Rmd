---
title: "5_Spore trao data analysis MODELTEST"
output: html_document
date: "2024-11-05"
---

```{r setup, include=FALSE}

library(readxl)
library(dplyr)
library(lme4)
library(caret)

```

```{r setup2}
# read LRdat for HPCC uploadd
LRdat<- read.csv(file = '/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Documents/Work/Spore Trapping/Code/HPCC/LRdat_noscale.csv') %>%
  select('thrs_0', 'SiteYear', starts_with('MA1_')) %>%
  select(1:15)

# note: LRdat is SCALED, LRdat_noscale is not 

```

```{r define formulas}

# Define the list of formulas

formulas <- c(
  'thrs_0 ~ 1 + MA1_temp_mean + (1 | SiteYear)',
  'thrs_0 ~ 1 + MA1_temp_min + (1 | SiteYear)',
  'thrs_0 ~ 1 + MA1_temp_min + MA1_hum_max + (1 | SiteYear)',
  'thrs_0 ~ 1 + MA1_temp_mean + MA1_hum_mean + (1 | SiteYear)',
  'thrs_0 ~ 1 + MA1_temp_mean + MA1_hum_min + (1 | SiteYear)',
  'thrs_0 ~ 1 + MA1_temp_mean + MA1_hum_max + (1 | SiteYear)',
  'thrs_0 ~ 1 + MA1_temp_min + MA1_WS_min + (1 | SiteYear)',
  'thrs_0 ~ 1 + MA1_temp_min + MA1_hum_max + MA1_WS_min + (1 | SiteYear)',
  'thrs_0 ~ 1 + MA1_temp_min + MA1_hum_max + MA1_Pcp_max + (1 | SiteYear)',
  'thrs_0 ~ 1 + MA1_temp_min + MA1_hum_max + MA1_WS_max + (1 | SiteYear)'
)

```

```{r balanced data set}

# Get the indices for each class
class_0_indices <- which(LRdat$thrs_0 == 0)
class_1_indices <- which(LRdat$thrs_0 == 1)

# Determine the minimum class size
min_class_size <- min(length(class_0_indices), length(class_1_indices))

# Randomly sample from both classes to ensure equal proportions
set.seed(123)  # Set seed for reproducibility
class_0_sample <- sample(class_0_indices, min_class_size)
class_1_sample <- sample(class_1_indices, min_class_size)

# Combine the sampled indices
LRdat <- LRdat[c(class_0_sample, class_1_sample), ]
```


```{r model fitting loop}

# Initialize a list to store results
performance_df <- data.frame(
  formula = character(),
  coefs = numeric(),
  aic = numeric(),
  kappa = numeric(),
  accuracy = numeric(),
  specificity = numeric(),
  sensitivity = numeric(),
  precision = numeric(),
  stringsAsFactors = FALSE
)

# Loop over each formula
for (formula in formulas) {
  
  # Fit the logistic regression model
  model <- glmer(as.formula(formula), data = LRdat, family = binomial)
  
  # Make predictions (predicted probabilities)
  pred_prob <- predict(model, type = "response")  # Predicted probabilities
  pred_class <- ifelse(pred_prob > 0.7, 1, 0)  # Convert to binary outcome
  
  # Make the confusion matrix
  trues <- LRdat$thrs_0
  conf_matrix <- confusionMatrix(factor(pred_class), factor(trues))

  # Add the results to a dataframe
  performance_df <- rbind(performance_df, data.frame(
    formula = as.character(formula),
    coefs = paste(names(fixef(model)), fixef(model), sep = ":", collapse = ", "),
    aic = AIC(model),
    kappa = conf_matrix$overall['Kappa'],
    accuracy = conf_matrix$overall['Accuracy']*100,
    specificity = conf_matrix$byClass['Specificity']*100,
    sensitivity = conf_matrix$byClass['Sensitivity']*100,
    precision = conf_matrix$byClass['Precision']*100,
    stringsAsFactors = FALSE
  ))
}

# Table for export

library(openxlsx)
# Specify the path to the Excel file
file_path <- '/Users/jilliancheck/Library/CloudStorage/OneDrive-MichiganStateUniversity/Documents/Work/Spore Trapping/Manuscript/Tables.xlsx'

# Check if the file exists
if (file.exists(file_path)) {
  # Load the existing workbook
  wb <- loadWorkbook(file_path)
  
  # Write the data to a specific sheet 
  writeData(wb, sheet = 'LOGREG RAW', performance_df, startCol = 1, startRow = 1)
} else {
  # Create a new workbook if the file doesn't exist
  wb <- createWorkbook()
  addWorksheet(wb, "Sheet1")
  writeData(wb, sheet = "Sheet1", data)
}

# Save the workbook - BE CAREFUL WITH OVERWRITING!
saveWorkbook(wb, file_path, overwrite = FALSE)

```

```{r}

library(lattice)

model <- glm(thrs_0 ~ 1 + MA1_temp_mean + MA1_hum_min, data=LRdat, family="binomial")

x_tilde <- expand.grid(MA1_temp_mean=seq(min(LRdat$MA1_temp_mean), max(LRdat$MA1_temp_mean), length.out=10), 
                       MA1_hum_min=seq(min(LRdat$MA1_hum_min), max(LRdat$MA1_hum_min), length.out=10))
x_tilde$prediction <- predict(model, x_tilde, type="response")

wireframe(prediction ~ MA1_temp_mean + MA1_hum_min, data=x_tilde,
    xlab = "Daily mean temperature",
          ylab = "Daily min humidity",
          drape = TRUE,
          colorkey = TRUE,
          scales = list(arrows=FALSE,cex=.5, tick.number = 10, z = list(arrows=F), distance =c(1.5, 1.5, 1.5)),
          light.source = c(10,0,10),
          col.regions = rainbow(100, s = 1, v = 1, start = 0, end = max(1,100 - 1)/100, alpha = .8),
          screen = list(z = -60, x = -60))
```
```{r}

# Load necessary libraries
library(plotly)

graph_reso = 1

# Fit the logistic regression model
model <- glm(thrs_0 ~ 1 + MA1_temp_mean + MA1_hum_min, data = LRdat, family = "binomial")

# Create a grid of new values for MA1_temp_mean and MA1_hum_min
x_tilde <- expand.grid(MA1_temp_mean = seq(min(LRdat$MA1_temp_mean), max(LRdat$MA1_temp_mean), by = graph_reso),
                       MA1_hum_min = seq(min(LRdat$MA1_hum_min), max(LRdat$MA1_hum_min), by = graph_reso))

# Use the model to predict the probabilities on the grid
x_tilde$prediction <- predict(model, x_tilde, type = "response")

# Reshape the prediction into a matrix for surface plotting
z_matrix <- matrix(x_tilde$prediction, 
                   nrow = length(unique(x_tilde$MA1_temp_mean)), 
                   ncol = length(unique(x_tilde$MA1_hum_min)))

# Create a surface plot using plot_ly
fig <- plot_ly(
  x = unique(x_tilde$MA1_temp_mean),
  y = unique(x_tilde$MA1_hum_min),
  z = z_matrix,
  type = 'surface') %>%
  layout(scene = list(xaxis = list(title = 'Mean temperature'),
                      yaxis = list(title = 'Minimum humidity (%)'),
                      zaxis = list(title = 'Predicted Probability')))

# Show the plot
fig

```

